{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1448,
   "id": "c1609a22-9008-4da2-874b-eab616062a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "id": "9dc8b6b3-c6d5-4d7f-9f11-1de32e3b42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "id": "0ae9eb3b-df27-43ad-911a-3ece90e8626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>country</th>\n",
       "      <th>url_x</th>\n",
       "      <th>driver_x</th>\n",
       "      <th>grid</th>\n",
       "      <th>podium</th>\n",
       "      <th>url_y</th>\n",
       "      <th>driver_points</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>...</th>\n",
       "      <th>nationality_French</th>\n",
       "      <th>nationality_German</th>\n",
       "      <th>nationality_Spanish</th>\n",
       "      <th>constructor_ferrari</th>\n",
       "      <th>constructor_force_india</th>\n",
       "      <th>constructor_mclaren</th>\n",
       "      <th>constructor_mercedes</th>\n",
       "      <th>constructor_red_bull</th>\n",
       "      <th>constructor_renault</th>\n",
       "      <th>constructor_williams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>michael_schumacher</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>massa</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>button</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>alonso</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>montoya</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2006_Bahrain_Gran...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  round  country                                              url_x  \\\n",
       "0    2006      1  Bahrain  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...   \n",
       "1    2006      1  Bahrain  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...   \n",
       "2    2006      1  Bahrain  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...   \n",
       "3    2006      1  Bahrain  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...   \n",
       "4    2006      1  Bahrain  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...   \n",
       "\n",
       "             driver_x  grid  podium  \\\n",
       "0  michael_schumacher     1       0   \n",
       "1               massa     2       0   \n",
       "2              button     3       0   \n",
       "3              alonso     4       1   \n",
       "4             montoya     5       0   \n",
       "\n",
       "                                               url_y  driver_points  \\\n",
       "0  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...              8   \n",
       "1  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...              0   \n",
       "2  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...              5   \n",
       "3  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...             10   \n",
       "4  http://en.wikipedia.org/wiki/2006_Bahrain_Gran...              4   \n",
       "\n",
       "   driver_wins  ...  nationality_French  nationality_German  \\\n",
       "0            0  ...               False                True   \n",
       "1            0  ...               False               False   \n",
       "2            0  ...               False               False   \n",
       "3            1  ...               False               False   \n",
       "4            0  ...               False               False   \n",
       "\n",
       "   nationality_Spanish  constructor_ferrari constructor_force_india  \\\n",
       "0                False                 True                   False   \n",
       "1                False                 True                   False   \n",
       "2                False                False                   False   \n",
       "3                 True                False                   False   \n",
       "4                False                False                   False   \n",
       "\n",
       "   constructor_mclaren  constructor_mercedes  constructor_red_bull  \\\n",
       "0                False                 False                 False   \n",
       "1                False                 False                 False   \n",
       "2                False                 False                 False   \n",
       "3                False                 False                 False   \n",
       "4                 True                 False                 False   \n",
       "\n",
       "   constructor_renault  constructor_williams  \n",
       "0                False                 False  \n",
       "1                False                 False  \n",
       "2                False                 False  \n",
       "3                 True                 False  \n",
       "4                False                 False  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 1450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()\n",
    "df.podium = df.podium.map(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "train = df[df.season <2019]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "id": "042d25e8-13a2-40e8-93ba-8f54bcc05985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: podium, dtype: int64"
      ]
     },
     "execution_count": 1451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['driver_x', 'country', 'podium', 'url_x', 'url_y', 'driver_y'], axis = 1)\n",
    "y_train = train.podium\n",
    "\n",
    "scaler = StandardScaler()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "id": "2a724865-fca1-4a6e-a8d1-4bae346b9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "id": "2e70c622-9278-4f5d-bcc7-22daa469884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential (\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(47, 75),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(75, 25),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(25,10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "id": "fcfd8f25-3d1f-4d50-b77b-b4cb72a5251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train.to_numpy())\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "id": "1219973c-27e1-4f4c-89c6-24f11ae6207d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=47, out_features=75, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=25, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = MLP()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "id": "adb0869d-88cf-4d6c-b74f-e9fc57a165b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), \n",
    "                            lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "id": "43c7048b-5d14-4e13-bafa-70eb4ba9195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 2.1283297538757324\n",
      "Epoch: 10 and loss: 2.0977118015289307\n",
      "Epoch: 20 and loss: 2.0672767162323\n",
      "Epoch: 30 and loss: 2.036799192428589\n",
      "Epoch: 40 and loss: 2.0060231685638428\n",
      "Epoch: 50 and loss: 1.9746789932250977\n",
      "Epoch: 60 and loss: 1.942529320716858\n",
      "Epoch: 70 and loss: 1.90923011302948\n",
      "Epoch: 80 and loss: 1.8746285438537598\n",
      "Epoch: 90 and loss: 1.8385237455368042\n",
      "Epoch: 100 and loss: 1.800746202468872\n",
      "Epoch: 110 and loss: 1.7611677646636963\n",
      "Epoch: 120 and loss: 1.7196108102798462\n",
      "Epoch: 130 and loss: 1.6759260892868042\n",
      "Epoch: 140 and loss: 1.6300727128982544\n",
      "Epoch: 150 and loss: 1.5820943117141724\n",
      "Epoch: 160 and loss: 1.532013177871704\n",
      "Epoch: 170 and loss: 1.4799139499664307\n",
      "Epoch: 180 and loss: 1.425998330116272\n",
      "Epoch: 190 and loss: 1.3705828189849854\n",
      "Epoch: 200 and loss: 1.3140714168548584\n",
      "Epoch: 210 and loss: 1.256737232208252\n",
      "Epoch: 220 and loss: 1.1989731788635254\n",
      "Epoch: 230 and loss: 1.1412169933319092\n",
      "Epoch: 240 and loss: 1.0839619636535645\n",
      "Epoch: 250 and loss: 1.0276788473129272\n",
      "Epoch: 260 and loss: 0.9727718234062195\n",
      "Epoch: 270 and loss: 0.9196888208389282\n",
      "Epoch: 280 and loss: 0.8687551021575928\n",
      "Epoch: 290 and loss: 0.8202536702156067\n",
      "Epoch: 300 and loss: 0.7744113802909851\n",
      "Epoch: 310 and loss: 0.7313531041145325\n",
      "Epoch: 320 and loss: 0.6911614537239075\n",
      "Epoch: 330 and loss: 0.6538371443748474\n",
      "Epoch: 340 and loss: 0.619318425655365\n",
      "Epoch: 350 and loss: 0.5874971747398376\n",
      "Epoch: 360 and loss: 0.5582391619682312\n",
      "Epoch: 370 and loss: 0.5314172506332397\n",
      "Epoch: 380 and loss: 0.5068761110305786\n",
      "Epoch: 390 and loss: 0.48444342613220215\n",
      "Epoch: 400 and loss: 0.46396923065185547\n",
      "Epoch: 410 and loss: 0.4452938437461853\n",
      "Epoch: 420 and loss: 0.42827197909355164\n",
      "Epoch: 430 and loss: 0.41275662183761597\n",
      "Epoch: 440 and loss: 0.39861050248146057\n",
      "Epoch: 450 and loss: 0.3856998085975647\n",
      "Epoch: 460 and loss: 0.3738943636417389\n",
      "Epoch: 470 and loss: 0.36307549476623535\n",
      "Epoch: 480 and loss: 0.35315215587615967\n",
      "Epoch: 490 and loss: 0.3440310060977936\n",
      "Epoch: 500 and loss: 0.33563148975372314\n",
      "Epoch: 510 and loss: 0.32787689566612244\n",
      "Epoch: 520 and loss: 0.32069727778434753\n",
      "Epoch: 530 and loss: 0.3140410780906677\n",
      "Epoch: 540 and loss: 0.30785560607910156\n",
      "Epoch: 550 and loss: 0.3020938038825989\n",
      "Epoch: 560 and loss: 0.296713262796402\n",
      "Epoch: 570 and loss: 0.29167720675468445\n",
      "Epoch: 580 and loss: 0.28695714473724365\n",
      "Epoch: 590 and loss: 0.2825262248516083\n",
      "Epoch: 600 and loss: 0.27835381031036377\n",
      "Epoch: 610 and loss: 0.27441415190696716\n",
      "Epoch: 620 and loss: 0.270687460899353\n",
      "Epoch: 630 and loss: 0.2671549916267395\n",
      "Epoch: 640 and loss: 0.26380082964897156\n",
      "Epoch: 650 and loss: 0.2606164515018463\n",
      "Epoch: 660 and loss: 0.25758737325668335\n",
      "Epoch: 670 and loss: 0.2547021508216858\n",
      "Epoch: 680 and loss: 0.2519518733024597\n",
      "Epoch: 690 and loss: 0.2493240237236023\n",
      "Epoch: 700 and loss: 0.2468094527721405\n",
      "Epoch: 710 and loss: 0.2443990558385849\n",
      "Epoch: 720 and loss: 0.24208694696426392\n",
      "Epoch: 730 and loss: 0.23986509442329407\n",
      "Epoch: 740 and loss: 0.2377207726240158\n",
      "Epoch: 750 and loss: 0.23565202951431274\n",
      "Epoch: 760 and loss: 0.2336556613445282\n",
      "Epoch: 770 and loss: 0.2317281812429428\n",
      "Epoch: 780 and loss: 0.2298649102449417\n",
      "Epoch: 790 and loss: 0.2280626893043518\n",
      "Epoch: 800 and loss: 0.22631610929965973\n",
      "Epoch: 810 and loss: 0.2246253341436386\n",
      "Epoch: 820 and loss: 0.22298690676689148\n",
      "Epoch: 830 and loss: 0.2214014083147049\n",
      "Epoch: 840 and loss: 0.21986359357833862\n",
      "Epoch: 850 and loss: 0.21836772561073303\n",
      "Epoch: 860 and loss: 0.21691277623176575\n",
      "Epoch: 870 and loss: 0.21549518406391144\n",
      "Epoch: 880 and loss: 0.21411269903182983\n",
      "Epoch: 890 and loss: 0.21276362240314484\n",
      "Epoch: 900 and loss: 0.2114497274160385\n",
      "Epoch: 910 and loss: 0.2101690024137497\n",
      "Epoch: 920 and loss: 0.20891934633255005\n",
      "Epoch: 930 and loss: 0.20769959688186646\n",
      "Epoch: 940 and loss: 0.20651140809059143\n",
      "Epoch: 950 and loss: 0.20534953474998474\n",
      "Epoch: 960 and loss: 0.20421400666236877\n",
      "Epoch: 970 and loss: 0.20310354232788086\n",
      "Epoch: 980 and loss: 0.20201876759529114\n",
      "Epoch: 990 and loss: 0.20095829665660858\n",
      "Epoch: 1000 and loss: 0.19992105662822723\n",
      "Epoch: 1010 and loss: 0.19890256226062775\n",
      "Epoch: 1020 and loss: 0.19790466129779816\n",
      "Epoch: 1030 and loss: 0.19692502915859222\n",
      "Epoch: 1040 and loss: 0.1959609091281891\n",
      "Epoch: 1050 and loss: 0.19501160085201263\n",
      "Epoch: 1060 and loss: 0.19407665729522705\n",
      "Epoch: 1070 and loss: 0.19315746426582336\n",
      "Epoch: 1080 and loss: 0.19225342571735382\n",
      "Epoch: 1090 and loss: 0.1913631558418274\n",
      "Epoch: 1100 and loss: 0.19048403203487396\n",
      "Epoch: 1110 and loss: 0.18961741030216217\n",
      "Epoch: 1120 and loss: 0.18876294791698456\n",
      "Epoch: 1130 and loss: 0.18792009353637695\n",
      "Epoch: 1140 and loss: 0.18708759546279907\n",
      "Epoch: 1150 and loss: 0.18626494705677032\n",
      "Epoch: 1160 and loss: 0.1854533851146698\n",
      "Epoch: 1170 and loss: 0.18465346097946167\n",
      "Epoch: 1180 and loss: 0.18386216461658478\n",
      "Epoch: 1190 and loss: 0.1830790936946869\n",
      "Epoch: 1200 and loss: 0.18230217695236206\n",
      "Epoch: 1210 and loss: 0.181535542011261\n",
      "Epoch: 1220 and loss: 0.18077963590621948\n",
      "Epoch: 1230 and loss: 0.1800326108932495\n",
      "Epoch: 1240 and loss: 0.17929543554782867\n",
      "Epoch: 1250 and loss: 0.1785655915737152\n",
      "Epoch: 1260 and loss: 0.17784224450588226\n",
      "Epoch: 1270 and loss: 0.17712529003620148\n",
      "Epoch: 1280 and loss: 0.17641296982765198\n",
      "Epoch: 1290 and loss: 0.17570887506008148\n",
      "Epoch: 1300 and loss: 0.17501133680343628\n",
      "Epoch: 1310 and loss: 0.1743229478597641\n",
      "Epoch: 1320 and loss: 0.17363975942134857\n",
      "Epoch: 1330 and loss: 0.17295542359352112\n",
      "Epoch: 1340 and loss: 0.17227201163768768\n",
      "Epoch: 1350 and loss: 0.17159494757652283\n",
      "Epoch: 1360 and loss: 0.1709280014038086\n",
      "Epoch: 1370 and loss: 0.1702663153409958\n",
      "Epoch: 1380 and loss: 0.1696099191904068\n",
      "Epoch: 1390 and loss: 0.16896454989910126\n",
      "Epoch: 1400 and loss: 0.1683269590139389\n",
      "Epoch: 1410 and loss: 0.16769640147686005\n",
      "Epoch: 1420 and loss: 0.16707094013690948\n",
      "Epoch: 1430 and loss: 0.16645076870918274\n",
      "Epoch: 1440 and loss: 0.16583865880966187\n",
      "Epoch: 1450 and loss: 0.16523200273513794\n",
      "Epoch: 1460 and loss: 0.16463066637516022\n",
      "Epoch: 1470 and loss: 0.16403183341026306\n",
      "Epoch: 1480 and loss: 0.1634368598461151\n",
      "Epoch: 1490 and loss: 0.1628452092409134\n",
      "Epoch: 1500 and loss: 0.16225352883338928\n",
      "Epoch: 1510 and loss: 0.16166259348392487\n",
      "Epoch: 1520 and loss: 0.16107341647148132\n",
      "Epoch: 1530 and loss: 0.1604861617088318\n",
      "Epoch: 1540 and loss: 0.15990358591079712\n",
      "Epoch: 1550 and loss: 0.159328892827034\n",
      "Epoch: 1560 and loss: 0.1587611883878708\n",
      "Epoch: 1570 and loss: 0.15819761157035828\n",
      "Epoch: 1580 and loss: 0.15763942897319794\n",
      "Epoch: 1590 and loss: 0.157085582613945\n",
      "Epoch: 1600 and loss: 0.15653280913829803\n",
      "Epoch: 1610 and loss: 0.155979722738266\n",
      "Epoch: 1620 and loss: 0.15542741119861603\n",
      "Epoch: 1630 and loss: 0.1548772007226944\n",
      "Epoch: 1640 and loss: 0.15432895720005035\n",
      "Epoch: 1650 and loss: 0.15378187596797943\n",
      "Epoch: 1660 and loss: 0.1532379388809204\n",
      "Epoch: 1670 and loss: 0.15269361436367035\n",
      "Epoch: 1680 and loss: 0.15215106308460236\n",
      "Epoch: 1690 and loss: 0.151615709066391\n",
      "Epoch: 1700 and loss: 0.1510828137397766\n",
      "Epoch: 1710 and loss: 0.1505519151687622\n",
      "Epoch: 1720 and loss: 0.150021493434906\n",
      "Epoch: 1730 and loss: 0.14949209988117218\n",
      "Epoch: 1740 and loss: 0.14896424114704132\n",
      "Epoch: 1750 and loss: 0.1484372466802597\n",
      "Epoch: 1760 and loss: 0.1479066014289856\n",
      "Epoch: 1770 and loss: 0.14738261699676514\n",
      "Epoch: 1780 and loss: 0.14685915410518646\n",
      "Epoch: 1790 and loss: 0.14633621275424957\n",
      "Epoch: 1800 and loss: 0.14581677317619324\n",
      "Epoch: 1810 and loss: 0.14530082046985626\n",
      "Epoch: 1820 and loss: 0.1447891891002655\n",
      "Epoch: 1830 and loss: 0.1442784070968628\n",
      "Epoch: 1840 and loss: 0.14377102255821228\n",
      "Epoch: 1850 and loss: 0.14327068626880646\n",
      "Epoch: 1860 and loss: 0.14277294278144836\n",
      "Epoch: 1870 and loss: 0.142276793718338\n",
      "Epoch: 1880 and loss: 0.14178389310836792\n",
      "Epoch: 1890 and loss: 0.14129124581813812\n",
      "Epoch: 1900 and loss: 0.14079873263835907\n",
      "Epoch: 1910 and loss: 0.14031106233596802\n",
      "Epoch: 1920 and loss: 0.13982392847537994\n",
      "Epoch: 1930 and loss: 0.1393386572599411\n",
      "Epoch: 1940 and loss: 0.1388564556837082\n",
      "Epoch: 1950 and loss: 0.1383776217699051\n",
      "Epoch: 1960 and loss: 0.13790231943130493\n",
      "Epoch: 1970 and loss: 0.13742835819721222\n",
      "Epoch: 1980 and loss: 0.1369571089744568\n",
      "Epoch: 1990 and loss: 0.13648463785648346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train our model!\n",
    "# Epochs? (one run thru all the training data in our network)\n",
    "epochs = 2000\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_function(y_pred, y_train) # predicted values vs the y_train\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "id": "7dd7d5aa-4044-4015-b362-445bac374d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorecard(season):\n",
    "    df = data.copy()\n",
    "    df.podium = df.podium.map(lambda x: 1 if x == 1 else 0)\n",
    "    score = 0\n",
    "    count = 0\n",
    "    for circuit in df[df.season == season]['round'].unique():\n",
    "        count +=1\n",
    "        test = df[(df.season == season) & (df['round'] == circuit) & (df['grid'] == 1)]\n",
    "    \n",
    "        winner = data[(data.season == season) & (data['round'] == circuit) & (data['podium'] == 1)].grid\n",
    "        try:\n",
    "            winner = winner.to_numpy()[0]\n",
    "        except:\n",
    "            winner = None\n",
    "        \n",
    "        X_test = test.drop(['driver_x', 'country', 'podium', 'url_x', 'url_y', 'driver_y'], axis = 1)\n",
    "        y_test = test.podium\n",
    "        #scaling\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "        X_test = torch.Tensor(X_test.to_numpy())\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            prediction = model(X_test)\n",
    "            prob = F.softmax(prediction, dim=1)\n",
    "            top_p, top_class = prob.topk(1, dim = 1)\n",
    "            if prediction.argmax().item() == y_test.to_numpy()[0]:\n",
    "                score+=1\n",
    "                print(f'CORRECTLY predicted the pole to {\"win\" if prediction.argmax().item() == 1 else \"lose\"} with {top_p}% confidence')\n",
    "            else:\n",
    "                print(f'INCORRECTLY predicted the pole to {\"win\" if prediction.argmax().item() == 1 else \"lose\"} with {top_p}% confidence')\n",
    "\n",
    "    print(f'{score} out of {count} races')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "id": "0674cf8d-0f85-48ad-9229-01d8f38c24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorecard_ts(season):\n",
    "    df = data.copy()\n",
    "    df.podium = df.podium.map(lambda x: 1 if x == 1 else 0)\n",
    "    score = 0\n",
    "    count = 0\n",
    "    predicted = 0\n",
    "    for circuit in df[df.season == season]['round'].unique():\n",
    "        count +=1\n",
    "        winner = data[(data.season == season) & (data['round'] == circuit) & (data['podium'] == 1)].grid\n",
    "        try:\n",
    "            winner = winner.to_numpy()[0]\n",
    "        except:\n",
    "            winner = None\n",
    "        model.eval()\n",
    "        for grid in range(20):\n",
    "            test = df[(df.season == season) & (df['round'] == circuit) & (df['grid'] == grid + 1)]  \n",
    "            X_test = test.drop(['driver_x', 'country', 'podium', 'url_x', 'url_y', 'driver_y'], axis = 1)\n",
    "            try:\n",
    "                X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "            except:\n",
    "                continue\n",
    "            X_test = torch.Tensor(X_test.to_numpy())\n",
    "            prediction = model(X_test)\n",
    "            if prediction.argmax().item():\n",
    "                predicted+=1\n",
    "                print(f'{\"CORRECTLY\" if grid+1 == winner else \"INCORRECTLY\"} predicted. P{grid+1} should win in round {circuit} (actual winner was P{winner})')\n",
    "                score+= 1 if grid+1 == winner else 0\n",
    "                break\n",
    "\n",
    "    print(f'{score} out of {predicted} predictedraces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "id": "2b000c0d-4b1c-4ec8-81dc-346cb6ada0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorecard_pole(season):\n",
    "    score = 0\n",
    "    count = 0\n",
    "    predicted = 0\n",
    "    for circuit in df[df.season == season]['round'].unique():\n",
    "        count +=1\n",
    "        try:\n",
    "            winner = data[(data.season == season) & (data['round'] == circuit) & (data['podium'] == 1)].grid.to_numpy()[0]\n",
    "        except:\n",
    "            continue\n",
    "        if winner == 1:\n",
    "            score+=1\n",
    "    print(f'{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "id": "396ccc77-b169-45c5-831f-c077eb43b6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY predicted. P1 should win in round 1 (actual winner was P1)\n",
      "CORRECTLY predicted. P1 should win in round 2 (actual winner was P1)\n",
      "CORRECTLY predicted. P1 should win in round 3 (actual winner was P1)\n",
      "INCORRECTLY predicted. P2 should win in round 4 (actual winner was P3)\n",
      "INCORRECTLY predicted. P1 should win in round 5 (actual winner was PNone)\n",
      "CORRECTLY predicted. P1 should win in round 6 (actual winner was P1)\n",
      "CORRECTLY predicted. P1 should win in round 7 (actual winner was P1)\n",
      "CORRECTLY predicted. P1 should win in round 8 (actual winner was P1)\n",
      "CORRECTLY predicted. P1 should win in round 9 (actual winner was P1)\n",
      "CORRECTLY predicted. P1 should win in round 10 (actual winner was P1)\n",
      "CORRECTLY predicted. P2 should win in round 11 (actual winner was P2)\n",
      "CORRECTLY predicted. P6 should win in round 12 (actual winner was P6)\n",
      "CORRECTLY predicted. P1 should win in round 13 (actual winner was P1)\n",
      "CORRECTLY predicted. P2 should win in round 14 (actual winner was P2)\n",
      "CORRECTLY predicted. P1 should win in round 16 (actual winner was P1)\n",
      "CORRECTLY predicted. P1 should win in round 17 (actual winner was P1)\n",
      "CORRECTLY predicted. P6 should win in round 18 (actual winner was P6)\n",
      "CORRECTLY predicted. P3 should win in round 19 (actual winner was P3)\n",
      "CORRECTLY predicted. P1 should win in round 20 (actual winner was P1)\n",
      "CORRECTLY predicted. P2 should win in round 21 (actual winner was P2)\n",
      "CORRECTLY predicted. P1 should win in round 22 (actual winner was P1)\n",
      "19 out of 21 predictedraces\n"
     ]
    }
   ],
   "source": [
    "scorecard_ts(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "id": "21384cce-3e46-4e81-b38f-195a67dc6d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY predicted the pole to win with tensor([[0.7993]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.5779]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.8604]])% confidence\n",
      "CORRECTLY predicted the pole to lose with tensor([[0.8583]])% confidence\n",
      "INCORRECTLY predicted the pole to win with tensor([[0.6558]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.8579]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.9527]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.8709]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.9742]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.9336]])% confidence\n",
      "CORRECTLY predicted the pole to lose with tensor([[0.9471]])% confidence\n",
      "CORRECTLY predicted the pole to lose with tensor([[0.9613]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.9450]])% confidence\n",
      "CORRECTLY predicted the pole to lose with tensor([[0.9227]])% confidence\n",
      "INCORRECTLY predicted the pole to lose with tensor([[0.9237]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.9646]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.9333]])% confidence\n",
      "CORRECTLY predicted the pole to lose with tensor([[0.9798]])% confidence\n",
      "CORRECTLY predicted the pole to lose with tensor([[0.9879]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.9524]])% confidence\n",
      "CORRECTLY predicted the pole to lose with tensor([[0.9847]])% confidence\n",
      "CORRECTLY predicted the pole to win with tensor([[0.9647]])% confidence\n",
      "20 out of 22 races\n"
     ]
    }
   ],
   "source": [
    "scorecard(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "id": "a8e68d84-6d88-43ec-a87e-4a8ac59e20c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "scorecard_pole(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc45bff-813c-48d0-8856-4c12a6422826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
